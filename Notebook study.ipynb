{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c3012f-408c-4eee-aa6b-507d075d7d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pymlpipe.tabular import PyMLPipe\n",
    "from pymlpipe.pymlpipeUI import start_ui\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import optuna\n",
    "\n",
    "from helper import objective\n",
    "from helper import get_model \n",
    "from helper import evaluate_for_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ecfcc8-3912-4db4-9c17-28961a1d1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPOSITORY_DATA_RAW = 'data raw'\n",
    "REPOSITORY_DATA_PREPROCESSED = 'data preprocessed'\n",
    "REPOSITORY_STUDIES = 'studies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e23686-439f-4304-9498-c210e940b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = PyMLPipe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059dbed-6531-4b87-a1e1-cb9f20ac0623",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c95613-5dfd-4aec-9529-6978bb160198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForexDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_date, X_now, X_previous_hour, X_previous_day, X_previous_week, X_previous_month, y_bid, y_ask, idx, \n",
    "                 n_previous_hour_values, n_previous_day_values, n_previous_week_values, n_previous_month_values, n_features):\n",
    "        \n",
    "        self.X_date = X_date[idx].astype(np.int32)\n",
    "        self.X_now = X_now[idx].astype(np.float32)\n",
    "        self.X_previous_hour = X_previous_hour[idx].astype(np.float32)\n",
    "        self.X_previous_day = X_previous_day[idx].astype(np.float32)\n",
    "        self.X_previous_week = X_previous_week[idx].astype(np.float32)\n",
    "        self.X_previous_month = X_previous_month[idx].astype(np.float32)\n",
    "        self.y_bid = y_bid[idx].astype(np.float32)\n",
    "        self.y_ask = y_ask[idx].astype(np.float32)\n",
    "        self.n_previous_hour_values = n_previous_hour_values\n",
    "        self.n_previous_day_values = n_previous_day_values\n",
    "        self.n_previous_week_values = n_previous_week_values\n",
    "        self.n_previous_month_values = n_previous_month_values\n",
    "        self.n_features = n_features\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.y_bid.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.X_date[idx], self.X_now[idx], self.X_previous_hour[idx], self.X_previous_day[idx], \\\n",
    "               self.X_previous_week[idx], self.X_previous_month[idx], self.y_bid[idx], self.y_ask[idx]\n",
    "    \n",
    "    def fit_scalers(self, scaler_now, scaler_previous_hour, scaler_previous_day, scaler_previous_week, scaler_previous_month, scaler_y_bid, scaler_y_ask):\n",
    "        \n",
    "        return scaler_now.fit(self.X_now), scaler_previous_hour.fit(self.X_previous_hour), scaler_previous_day.fit(self.X_previous_day), \\\n",
    "               scaler_previous_week.fit(self.X_previous_week), scaler_previous_month.fit(self.X_previous_month), \\\n",
    "               scaler_y_bid.fit(np.expand_dims(self.y_bid, axis=1)), scaler_y_ask.fit(np.expand_dims(self.y_ask, axis=1))\n",
    "    \n",
    "    def scale(self, scaler_now, scaler_previous_hour, scaler_previous_day, scaler_previous_week, scaler_previous_month, scaler_y_bid, scaler_y_ask):\n",
    "        \n",
    "        self.X_now = scaler_now.transform(self.X_now)\n",
    "        self.X_previous_hour = scaler_previous_hour.transform(self.X_previous_hour).reshape(self.X_previous_hour.shape[0], self.n_previous_hour_values, self.n_features)\n",
    "        self.X_previous_day = scaler_previous_day.transform(self.X_previous_day).reshape(self.X_previous_day.shape[0], self.n_previous_day_values, self.n_features)\n",
    "        self.X_previous_week = scaler_previous_week.transform(self.X_previous_week).reshape(self.X_previous_week.shape[0], self.n_previous_week_values, self.n_features)\n",
    "        self.X_previous_month = scaler_previous_month.transform(self.X_previous_month).reshape(self.X_previous_month.shape[0], self.n_previous_month_values, self.n_features)\n",
    "        self.y_bid = np.squeeze(scaler_y_bid.transform(np.expand_dims(self.y_bid, axis=1)))\n",
    "        self.y_ask = np.squeeze(scaler_y_ask.transform(np.expand_dims(self.y_ask, axis=1)))\n",
    "        \n",
    "    def transfer_to_tensor(self):\n",
    "        \n",
    "        self.X_date = torch.from_numpy(self.X_date)\n",
    "        self.X_now = torch.from_numpy(self.X_now)\n",
    "        self.X_previous_hour = torch.from_numpy(self.X_previous_hour)\n",
    "        self.X_previous_day = torch.from_numpy(self.X_previous_day)\n",
    "        self.X_previous_week = torch.from_numpy(self.X_previous_week)\n",
    "        self.X_previous_month = torch.from_numpy(self.X_previous_month)\n",
    "        self.y_bid = torch.from_numpy(self.y_bid)\n",
    "        self.y_ask = torch.from_numpy(self.y_ask)\n",
    "        \n",
    "    def cuda(self):\n",
    "        \n",
    "        self.X_date = self.X_date.cuda()\n",
    "        self.X_now = self.X_now.cuda()\n",
    "        self.X_previous_hour = self.X_previous_hour.cuda()\n",
    "        self.X_previous_day = self.X_previous_day.cuda()\n",
    "        self.X_previous_week = self.X_previous_week.cuda()\n",
    "        self.X_previous_month = self.X_previous_month.cuda()\n",
    "        self.y_bid = self.y_bid.cuda()\n",
    "        self.y_ask = self.y_ask.cuda()\n",
    "        \n",
    "    def cpu(self):\n",
    "        \n",
    "        self.X_date = self.X_date.cpu()\n",
    "        self.X_now = self.X_now.cpu()\n",
    "        self.X_previous_hour = self.X_previous_hour.cpu()\n",
    "        self.X_previous_day = self.X_previous_day.cpu()\n",
    "        self.X_previous_week = self.X_previous_week.cpu()\n",
    "        self.X_previous_month = self.X_previous_month.cpu()\n",
    "        self.y_bid = self.y_bid.cpu()\n",
    "        self.y_ask = self.y_ask.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069126e-e906-40e3-bd78-1036877f4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tuning_trains = []\n",
    "dataset_tuning_validations = []\n",
    "\n",
    "for i in range(4):\n",
    "        \n",
    "    with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_tuning_train_' + str(i) + '.pt'), 'rb') as file:\n",
    "        dataset_tuning_trains.append(torch.load(file, pickle_module=pickle))\n",
    "            \n",
    "    with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_tuning_validation_' + str(i) + '.pt'), 'rb') as file:\n",
    "        dataset_tuning_validations.append(torch.load(file, pickle_module=pickle))\n",
    "        \n",
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_eval_train.pt'), 'rb') as file:\n",
    "    dataset_eval_train = torch.load(file, pickle_module=pickle)\n",
    "    \n",
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_eval_validation.pt'), 'rb') as file:\n",
    "    dataset_eval_validation = torch.load(file, pickle_module=pickle)\n",
    "    \n",
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_eval_test.pt'), 'rb') as file:\n",
    "    dataset_eval_test = torch.load(file, pickle_module=pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3b082-309a-4a42-8527-de28ce592f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'scaler_y_bid.pkl'), 'rb') as file:\n",
    "    scaler_y_bid = pickle.load(file)\n",
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'scaler_y_ask.pkl'), 'rb') as file:\n",
    "    scaler_y_ask = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5944eb4-9e4f-4355-9ce9-8970dbe0ebb1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Y bid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4640bf-0f47-434f-9091-9f41b0ebafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'y_bid'\n",
    "mlp.set_experiment(\"Forex EUR CHF Bid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b79c47-2019-4590-b06b-3945bbbe4d2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62198aa-ce82-471b-84f5-448e44f61150",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd37b7-9881-4cd1-98db-34ec2ef3241e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12342af8-401b-4d52-89e7-54c011417b84",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a437aa8-936a-40d6-a8a6-b8033f46fcb3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559bd5eb-2443-4722-8482-37728cb08b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3570e29-759a-4722-b2b8-e7099c78f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5058dbd3-3c97-4a1e-8811-6f9f33b3f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc514ff2-07dd-4d95-b5eb-96150fa8c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca5257-30f0-4776-88ea-1db9e98acb51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b2221d-9946-4b1a-bb96-e22acd326858",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03652bf-e99a-4856-8073-9b7273ca6066",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b463debf-8a50-4741-9dec-7b6b2093cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3045dfc-46b5-45e9-b30c-65047f25ea69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1eb34294-e9f4-4b1f-9a83-566ae37e51f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaca65c-33fe-4097-850a-701b851a6a38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba20365-ef54-4a9b-b1ce-e58f9dd9ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc6695-26c8-4aa3-84ed-fbe8689a004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a72b2e0-6b00-4d06-bd69-cf68cbe94e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f72fca-eb81-43e2-a680-17e237be5d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aa9abc-90b1-4aad-be32-0277718d4bd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0545cdf-9e63-4d89-afea-8cf12a76213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01334c35-0ed4-47b0-98ba-f617982ca40d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f0b1f8-6476-4d7c-9845-b9bf353503af",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e581017-b268-4511-8fa1-08582ac20234",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9b94d78-748e-447e-acf9-88699c27cebd",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a832fc5-5f74-4215-ab48-99357bda55e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84b7b2-e258-42c6-bc9f-ba0cd991ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad34ef-7f4c-4ec6-b034-bfa8e9d64a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53aeac6-4898-4582-b6e3-0fbdd41a1171",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb923d-c65b-4f58-b95a-a194717e7ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd45c43-061b-4bdf-b42f-e71d7d71edd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54cfc6-0c3c-4446-9490-55f2b872ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e343039-b2c4-475e-877a-dd31acdce43f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba045f2-89da-4049-ae8e-34c5b69fe9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5af836-abde-482d-a4f5-ccfd6e0092d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c3d0c5d-4f53-40a7-a390-a4fddfd16247",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95eb0fd-4b0d-4f80-b846-4874e2dad17b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26423208-4e05-4d81-8a46-3ad238490d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379c340-4817-43bc-83bc-1df9b3003cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ed58f-b4d5-44bf-82c5-2c4c5b8b213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8b0d5-0e98-4347-a18f-c97dc73c6158",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb640c17-1c84-42da-acb8-b9d972580764",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9b3c6a-0567-4af4-b2e3-8d513716801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232add51-af39-4648-bf91-4d086596f14d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315357fa-bce1-4666-b3cf-7eabdb717944",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe9251-b361-4079-9a2c-959bfcc60019",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ee97929-8251-4d33-a6f5-cb940fca922c",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae60004-1e94-487f-99b0-88d46ee2c546",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cfa080-d16b-46a4-97f5-db3ac8307c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e57678-6b58-4d00-8e45-aa8ac2dee40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8035f47-cca7-4895-a452-f2bac2719e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded0a5a-58e6-42d7-ad60-faa2241ef150",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15d352a-0a9b-4de5-817c-ee6b47dfcd70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a0e2ca-5746-4c87-8689-ce2d624eb804",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4163a561-b381-449e-933d-912475a8ba78",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3443b4c9-2114-418f-9c20-e2bbdb8a6bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a122d2e-57b5-4da4-b589-9b170d8c74cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "908e56ca-ee80-4030-b613-157d1c3ee851",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9415b5b-55fa-4a47-9158-fafe60a7a949",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0eb590-fa30-4501-9d72-6f4820cac7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2a47ba-e811-42d9-998b-0da8a821af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693fbca-95db-497f-a02a-1fc9e99b6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f661b-8dfc-4544-92bf-f392f1f68d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a558051-6106-4d01-abc3-20c2c0737988",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957387d7-2bee-4d57-a84a-b0400c45621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d2836-0387-41b6-988c-3de5f127464e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e6180-3088-4c93-865b-ee4c2775daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae4f658-9749-471c-9eea-07a896f43e53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4a12a9d-aefb-4ede-b2b5-399a7adaac8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8311de05-c47e-4c15-bd01-f88f2cc6bf5c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6af114-f0c7-49e9-89cf-7e8a95b1347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b98d7-c460-4ca1-85e5-1db3c1605e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e3bd6-c10f-405d-9252-f73abe82e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da8c3e-aa8e-4db7-bea3-9fac197bb0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc98615-ad54-40da-82dc-ff7cb0a5485d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663b3621-4253-407b-986b-f476d6f0a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180a3b1-09f8-4093-8a06-00dd04c30148",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13121d80-dedf-44c2-b2ca-1b0cc1779685",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81346c3-b8b3-40c3-a826-9b14c25c8929",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64bcdc83-f749-4293-9ec3-9db940a83b14",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d94d98-d708-456e-b4bd-b13eb7b9a1d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13afaf45-1dc0-46ca-943d-e519b7978b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea32c67e-7623-4f2f-b71e-de6fc6d6292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ce8cb7-ef48-411e-91ad-c4f4031f6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c5364-5bae-4043-98c1-5b6896f1efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80138b1-6a0c-4975-ae5e-1a133a9d2572",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce116b43-1d51-407c-848a-a96a82f18e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5ea023-a21f-45d8-af37-b1f672205aed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f6bf4-ee9a-4ba9-8fc0-06b9422b6748",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818a154-ed62-4c0f-8ca6-1f9fac9367e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0178f38-ccc3-47d6-800d-bd101b450989",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892e48c0-9fc5-4042-9115-a474a5f3d806",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b80ff30-cef1-4787-9268-687107503c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5068eaa3-d80d-4850-b434-7326abc08dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8a3f0-439c-4733-9ff1-09510e545602",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085afe78-c54a-4ace-a81f-32982a7cf4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b192e25-12db-4d50-a31a-5cf74b11719c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48771e81-baf3-47cc-9569-bca2300c2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772cbd16-ee09-4fa5-b4b9-a23fbedc2a1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9e9dad-d7b4-4d36-acbc-e9f2ea959451",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de679be8-e019-4bbc-9425-3515d571889e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3ee2e06-2285-4744-a726-5f5caa8250bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2c60f5-28f3-46df-9e05-16a579626a49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7b1eb-a794-4a74-a3d4-adcc85c2499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4122f064-fb79-461c-9617-2eec386d8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeabc90-a331-41d8-b838-814a64e33031",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f030be-7c89-4e5e-b239-754cdfc0f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c33972-102c-4e76-8f85-cf6c58ffd16f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfeeab-1082-4d9b-b012-e32975c760de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a4f0af-b084-44f6-bf0c-407762f3a5e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89753a56-b64a-418a-8694-73d162c600fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c80e40f-e7a8-49ef-b55c-d8103d33175e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58ad8274-72aa-4ace-9667-0290a156774a",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a04db1b-6faf-4be2-8cd1-57183b3e83bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ef2cb-4597-4106-b9bc-922058580bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31996b15-af99-4745-81c5-b35bfb6b957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f8f4d7-b1c1-4245-9cf5-068a227986dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0380d-09e0-4127-98c9-72c2ae7e3080",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3012cf-baaf-4c12-9b0a-e056ad7bcaa8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e084abce-625a-44ba-83a1-31d23c00cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c16aff-87a7-4b7d-9b56-ce0482058ba1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3cd941-029b-43c8-8c18-006f5818894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab81b5-f444-4737-87fd-29e0e0d6cc5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c24c8741-cc67-4e26-b539-3a34ac4be23e",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31587819-1ce9-4423-ae03-44c4fc8de120",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a510b8df-2306-4c28-b917-9b04c7ff41b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07435ef-421c-47f5-a7dd-16fb1fc1880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066c7d2-11be-4a7e-9362-c1b46fac408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62007004-3df3-4086-a08b-ff31730f2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b13dc92-b12c-4e00-92c2-4567753bd72f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f199fa1-6fca-41ac-b67c-d1c12e5b5ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed69ca3-08d0-4a5d-bd84-76b6599dcea1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2f4bd-a4e2-42e5-ac32-d09fac62655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c719ea6f-74ce-46b7-b54a-293b4a4c4043",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e5b9a9b-277e-44a2-84e7-0279dbef663a",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d8e6b-ce74-4c0e-a9b2-1b16db84316d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a71cc-4414-4287-bdaf-f4b3baca28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8378dd66-1ee1-4130-8bd2-3b89bb2a1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cf3e27-54ab-497d-ba7a-821d27bef8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b914f9-6729-4e83-baa3-6a2afc1cfc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a828eb11-55a0-4d2f-a056-d5709cc0b70e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c2288f-c08e-492c-babe-491718742607",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a7d842-f4f6-4a13-9afa-2259b0bdc8f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a204fd-2b2e-44bf-b329-88448253c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2189f0-300a-4afa-aa02-abc462f6d80d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c25daca-54c8-4f2d-882f-30bd807e535b",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec62e68-7255-4d62-9a9e-1542d05dce97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5920d4-a041-460c-8071-b58d12d73566",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0abecc5-c214-426f-9547-0b5ec08bac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da6e8a-8e81-4b5a-b63b-d3965692d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f51af3-1d53-46eb-8f01-29262dc874e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e574a487-edde-4a3d-852e-f4e545d61972",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea6a2a-0888-4513-9577-d37c4bb4b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12966e57-cacd-49ae-b2da-159437089550",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6764a5d-e4df-430c-9ac1-095b94ef744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0a6a82-09da-4b63-919b-3c45fedb3186",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba877260-dede-4591-91a1-5d58d14ce52c",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8109957-af4d-4920-ad60-3aad91891f5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97734f7-27ca-4e74-9074-be36d89f5130",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2403e077-77ab-40c3-b522-8918959b923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c3729-a0a6-4b4d-84df-303cb817c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372c8b0f-c4a6-42cd-a900-a07f36cfaf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3e9671-0b44-436c-9421-38246562e9b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c21900-3075-4569-9c53-9724f375642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486f6d1-f764-4b00-856e-7b9d059e9c3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d125dca-1700-4827-bb7b-d1ed1aeed7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe7d8df-78db-4c6b-b83e-5b2eed347d79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e790ca15-f885-400b-8c4e-d45f66d3df01",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6521bc73-95a9-4675-af57-bf22b5679f30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d458b-eded-4864-afbb-2bbec4a81ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c7b8be-44af-426b-98b0-d40b11a26b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc4843-68ed-4e31-919e-4e8ca791de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d52d80a-edc7-4d86-bf8c-6d871b21a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31223e5d-3332-43d1-8b57-dda3fcb04222",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a347b54e-5d38-4e7b-ae16-c674ec6232a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3825a585-4a27-4d90-97bf-89207f639e65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Y ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec9fd5d-24b5-458d-91bb-024825f2dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'y_ask'\n",
    "mlp.set_experiment(\"Forex EUR CHF Ask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3736f477-7aa0-41b3-b3bd-475fd809cf0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e162016a-ef9f-43f7-8a48-0b47b9f31a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c287840-c803-45b1-90c0-e78805832511",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71d33cbb-f8b7-4228-afcf-59c5bdfb6387",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95dc09a-c059-4fef-9032-f90bae2882bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a85e3-593c-4c7b-8995-14ad7a1a86b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3685869f-af0d-4f4d-82c5-6f2fe58a4abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bbce80-e234-4fe9-a17b-8ae56a2a43b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48a26af-4a90-4d8d-9253-55ca4cfc70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7398c577-32fc-40c1-8f70-dfe388cb124b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afd85e7-b265-4b34-8461-f377529c0f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67388f8-75d6-4248-9fbf-59bfcb5ba724",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7db14-f17e-4823-921b-674f0dc89111",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a0e054-4fe9-4d3e-9247-1cf9d89e9053",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1006ec94-32aa-4a56-9f4a-39826c9300fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3b59c5-99f9-49b2-9822-79c9598b46de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06157061-fb80-4c73-a450-9336d5a4c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95daf431-1fd1-41fe-be09-c925e8784d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d18e2-fd01-483b-9463-838ec31edfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e121c1fe-badf-4dcd-a667-290b3a06782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe54841-b7f0-4625-b52a-0e8aac5858c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e4198-eadf-4839-8fb5-adb6676e6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda4dbf2-f588-4fc9-9c4d-ecd24a8a4f98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f349d2-5f3d-4cab-a90b-7ddaa1ae9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34d2085-d442-4fa0-934f-8a942f4b6274",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6221e6a-1b98-4ee0-9751-aa3d4e5dfc80",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51035a00-f05b-49ba-9119-c4df080cb1db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd7c81-bf25-42a4-b658-3e997a8866eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64024539-bfd6-423d-8ed3-4de6f0ab1f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b5a4af-78b2-4ad7-9262-32d65c520e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf07ea0-1a63-4f32-a821-6b5cf62c22f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3480cf70-8fb7-4b69-b8d1-65048e6fd383",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b059050a-cb67-40a1-bc93-209247da2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ba0a6a-042d-43b6-b7f2-1956dea15dbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93f34e-e65d-444c-94f7-83298e65bead",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009bc2da-f0cf-44cd-b9a2-feef75780ae2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38789dd4-541e-44d0-bb35-a8b1db39becc",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364733a3-4951-44e6-a254-a2dc3265bfe0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b312e5d-3f2e-4b1d-8129-5c0f409d5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe03f83-e47c-4f96-815d-3623dce76405",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcaebaa-62eb-4dc8-9660-2a122dac89c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d35ba57-d1d1-4aa7-8ebb-ca3614728e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d2d25b-57dd-4e07-bd45-d708b9f7b152",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f41535-6c04-4527-a08f-efe52c44a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb161f33-d754-4a11-b9c7-f8059e51e7c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8a4ddc-0ac5-4ba7-aea8-27d570521d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a18eec1-4377-43a5-8b78-97a47939a531",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7da9a5c-3b9a-4a61-ad70-3188422bf16a",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f090a0-8e91-48d8-b280-afd5a3428a3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4d195a-df96-4fef-a90d-52952372a794",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb2d63-59eb-453a-8e2f-ad9401dc58e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7ccec9-c9a0-4be9-becf-4725bb69d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b0654-3a64-413c-bc01-196722ca1090",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ebe8a5-af79-4032-a87a-f544fcaf00d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665e53f-f1e8-4820-b426-ce44e70766a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0eb6b6-1816-4136-abf6-91c626a038d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888dfeea-29ef-4d27-bade-b96792b81bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cac878-e07d-4cc3-a086-386d57b6e1ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69c9e26c-b962-4d1e-9538-b3390fd2112a",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a00ae8c-b112-4a6f-889c-b34de77a2305",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6928d03c-ae92-4893-83f4-304c9aa88c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b36c990-8f4d-4e2d-8c96-920e9fbe4c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d226d73-54b1-479d-9680-407b6d273738",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646de8fa-08a0-42c2-bb8a-b6e7b452ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb06dd7c-97d5-4cd1-aa91-a40472c087fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b1be26-170a-42d9-b955-39d25f5dc864",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a15b1-6a7d-4ec6-9a7f-70080854ae99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbe0a21-23d9-478e-b8ca-f2896afcddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5103e9-cd96-4d62-bb5f-4680f5080d2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0af3cd41-33a5-4d9c-bc88-6f67f796c8f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fee6ca-d8a6-4819-8a65-dfbcbc3ef895",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb00f0-b415-4c4d-ac42-85c394b49aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc0c263-b3c2-466f-b751-c6f4e324dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f450d-a81c-4749-b404-da5667ca9939",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0910a13-61fa-40f6-949d-00c314f1730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96d0f7b-a618-4870-9b5e-5eeefb00611f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518618d1-8864-4148-95bc-17b321259559",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05846b7-015e-4d4d-951b-98a50fc00b4f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4fb04-43c6-4aac-b137-d954a708c09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e58da4-e4d5-4a90-ab15-c82b7e7bd2c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de8e3494-1439-42f1-ab2f-91c3d7105913",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae62c07-fef9-4198-b379-9d292b84892f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a48dd20-c4e0-47da-a671-cd516e6bb247",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342eb16-80ee-42c5-83b7-4dff539fb587",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f024785-b824-4661-b010-7060d79b1326",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5fa7f1-27f4-4be1-9e85-1dc937e26f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e45637-a449-47c9-ace0-958ab011f0bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8cd91e-3f0f-43eb-abf4-961592f603b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e93db7-8f58-4740-942d-bfdabafe402c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c772a7b-db18-4d71-9c7d-5547686ad52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798d6a61-a84a-4847-81f1-f7c1ab856344",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "925b91fa-5fde-4100-a793-dd63a650e381",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ac2a5d-6b76-45e9-8885-123f000ac0b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e709c857-2a49-4309-9e41-ade0cea706f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e8d25-dad0-4e19-8b19-5939f3592020",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49096e7c-4b6f-4e2c-a4fd-30fd3bc61f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6685a7ad-8ed4-45de-b0b0-14dce1704197",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4549a44c-af2a-47a8-b813-f7bf0ba4357e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd90fa5-07d2-459c-b1bc-4081608c2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704d0c2-775b-4a2a-9bd0-9183654136e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976c274-4a40-484c-8a14-6523424d75c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d2c639-0384-4a8e-b972-60a66b0277b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8b6a315-ff82-44da-a5b6-123731715fec",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308a3c7c-bc48-437a-b016-3368588d13ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3ab6c-a177-4999-bac8-6b6c466dad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf35d2f6-2342-4de1-a33b-33e6927745b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81508246-358e-4c53-98dd-e9ec54c7e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49c1e6-b053-4ba9-a8a6-40994b9c0773",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a543431-3085-465f-a331-a179a016ae87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e7817-f951-4902-baf9-8c76471c0c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad721b-7586-4414-a5c2-27610e3d1942",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a854362c-a8af-480d-8540-58017bfd0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c8ccbf-9d13-432c-81c9-fa6d96dc5ed4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c34c922c-a856-429b-870a-be10914fd730",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee1e71e-a540-40db-baf9-07c7a2f94cba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c047f-1f9c-4cab-8c7a-83582c348c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2150a8e-a145-4333-930d-8275c0c70f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76db8860-53a9-4e82-bf6e-1b385165fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef46dc-63c0-4162-adc9-cef2cd344da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7650d0-4de1-47bb-a794-39caba06b5c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e776170a-5fe0-43f6-b636-7c6f710daedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3dbe92-b65f-4034-887e-3795f0609c2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf028a-1c16-4fc6-a5af-0d513c320518",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886d3d89-4be9-402d-bfae-43fa220c655e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "837bb57c-329d-49d2-a5e0-19816a7c343e",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c688a2d8-045f-4e91-852c-0b219f1143f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9586320d-632c-4a2f-bfd7-2571babea9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1e69c-6884-4cf1-b8f7-e9516da1ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080de0f7-9bcd-4696-8ea6-90d7a7f449b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8738c0e4-22d8-40d0-aea9-eac6dad5f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0566df7-1366-4136-8b28-db2f4b55c1ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306fc84-935d-4abc-914e-04bf67acf04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a71781-49f5-419e-9c88-468f0aece90b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb15c84-2797-4f28-b733-045d91c1cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98722b-b566-4908-bfb4-d4c0b65a6380",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95f62991-a29b-4181-a790-6b1107b8dea1",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e0ea3-b27f-467b-b5d0-73ccc6cc6acc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64404be2-c0f2-4b60-ac59-b3b248f17f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83119d12-93f8-41d9-9a06-5affb4ec837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa9cb1-86e6-4326-bbeb-df0cc0a79705",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7eed2-fa37-4547-823e-2a4763fb348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fd9bb2-6429-4a62-87f9-dce12c1d64ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02e16c6-2b37-4370-9ab5-2a923dfb96fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7331f8c-2fbb-45d0-9d3a-8f6cd309d257",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e5671-d1e6-4cf7-b682-a6825cf47f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5328c8c-314d-4932-ad3f-a0f191be840e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc55748a-6b2b-4315-8fa8-d4f2d18fe94a",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80a1468-2e8d-4faa-9e02-c3014f7ea2ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5776f-9618-4a1f-b4d2-5f932d23048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b917a77c-b041-42c7-a4ae-c88502e25927",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f7aac-e08a-4dfc-86a1-7bd3d917aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8266e-3465-48fb-8517-e7430b12eefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b17f54-95e6-4e21-9599-300eb872b3b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda76489-7505-43a8-93f2-74123e1d8b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c2e689-fa4f-4ce7-baa3-1eb413611394",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef80844-72ae-44fc-84b3-83e998e5500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeee529-b7e1-4356-b96e-1c6c0c2ae25c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4c9f7ca-601c-497f-9e11-379fd574b0e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d288c4f-2e77-4fce-af17-00172ab35285",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cfd743-57b8-4758-99c6-252844679e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d741fd80-5ed3-4a69-9fc9-458e41cfd7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f114e18d-8952-4f18-9418-dfa6af2ea020",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de6a12-f380-4068-95b7-66bcd2e00e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28310c8-ebd5-4310-80b2-919a099e679e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07a765-24d5-448d-8d4c-8962957fd0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be3dc43-f8c6-47eb-b628-9882e81873cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078548e8-d4e6-4428-9884-7764f06e6a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a32c18-b993-489f-9915-6adaa124ff72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "67994441-db5f-4bec-8bf6-8ecbd382c2c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8967c43-87b8-486a-a6e3-479aedb567b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b91ee-da44-43a3-8dfb-441c0b18ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9bf3fd-74ac-4eb3-8faf-69692bfd9aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f69f364-870e-4f5c-bc3d-cf7555768ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1efe9f6-6f47-4cfa-968d-7516ad5f3a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1995aff0-01ce-4d0e-a275-77a33933557a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d858c0-a54e-4dfd-9aca-d1804e388dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7048ba8b-642f-4ce4-9ec8-ea6ceb396712",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb664e74-b381-4cd7-97e0-57bea879a0dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3fe6a661-1bf5-482d-a0cc-e4e620e4dac4",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b4013d-53e1-416c-96fc-ab0668a5ff01",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5b9f99-3b27-4f27-bec8-0875e62428e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be4dc24-ed65-4dc0-af51-d742fc07a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da7c71-28f5-4946-9d48-abb809dded5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e4647-0373-407b-9a18-de6729f39480",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d03a6-9e6b-429d-bbc3-498af204a34f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c876b7-56a0-4840-9425-1720a44fd652",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59abfc47-5902-484d-965c-686d62f8f31c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UI MlOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479dc04e-797a-4efb-b07b-b3f5e1c4632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ui(host='0.0.0.0', port=8085)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c8325-1401-4ea2-9fd8-3064a0c88e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
