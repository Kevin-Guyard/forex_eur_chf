{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c3012f-408c-4eee-aa6b-507d075d7d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pymlpipe.tabular import PyMLPipe\n",
    "from pymlpipe.pymlpipeUI import start_ui\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import optuna\n",
    "\n",
    "from helper import objective\n",
    "from helper import get_model \n",
    "from helper import evaluate_for_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8ecfcc8-3912-4db4-9c17-28961a1d1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPOSITORY_DATA_RAW = 'data raw'\n",
    "REPOSITORY_DATA_PREPROCESSED = 'data preprocessed'\n",
    "REPOSITORY_STUDIES = 'studies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e23686-439f-4304-9498-c210e940b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = PyMLPipe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059dbed-6531-4b87-a1e1-cb9f20ac0623",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380d09b8-4f46-40a3-b520-8c9f18163ff3",
   "metadata": {},
   "source": [
    "Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27c95613-5dfd-4aec-9529-6978bb160198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForexDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_date, X_now, X_previous_hour, X_previous_day, X_previous_week, X_previous_month, y_bid, y_ask, idx, \n",
    "                 n_previous_hour_values, n_previous_day_values, n_previous_week_values, n_previous_month_values, n_features):\n",
    "        \n",
    "        self.X_date = X_date[idx].astype(np.int32)\n",
    "        self.X_now = X_now[idx].astype(np.float32)\n",
    "        self.X_previous_hour = X_previous_hour[idx].astype(np.float32)\n",
    "        self.X_previous_day = X_previous_day[idx].astype(np.float32)\n",
    "        self.X_previous_week = X_previous_week[idx].astype(np.float32)\n",
    "        self.X_previous_month = X_previous_month[idx].astype(np.float32)\n",
    "        self.y_bid = y_bid[idx].astype(np.float32)\n",
    "        self.y_ask = y_ask[idx].astype(np.float32)\n",
    "        self.n_previous_hour_values = n_previous_hour_values\n",
    "        self.n_previous_day_values = n_previous_day_values\n",
    "        self.n_previous_week_values = n_previous_week_values\n",
    "        self.n_previous_month_values = n_previous_month_values\n",
    "        self.n_features = n_features\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.y_bid.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.X_date[idx], self.X_now[idx], self.X_previous_hour[idx], self.X_previous_day[idx], \\\n",
    "               self.X_previous_week[idx], self.X_previous_month[idx], self.y_bid[idx], self.y_ask[idx]\n",
    "    \n",
    "    def fit_scalers(self, scaler_now, scaler_previous_hour, scaler_previous_day, scaler_previous_week, scaler_previous_month, scaler_y_bid, scaler_y_ask):\n",
    "        \n",
    "        return scaler_now.fit(self.X_now), scaler_previous_hour.fit(self.X_previous_hour), scaler_previous_day.fit(self.X_previous_day), \\\n",
    "               scaler_previous_week.fit(self.X_previous_week), scaler_previous_month.fit(self.X_previous_month), \\\n",
    "               scaler_y_bid.fit(np.expand_dims(self.y_bid, axis=1)), scaler_y_ask.fit(np.expand_dims(self.y_ask, axis=1))\n",
    "    \n",
    "    def scale(self, scaler_now, scaler_previous_hour, scaler_previous_day, scaler_previous_week, scaler_previous_month, scaler_y_bid, scaler_y_ask):\n",
    "        \n",
    "        self.X_now = scaler_now.transform(self.X_now)\n",
    "        self.X_previous_hour = scaler_previous_hour.transform(self.X_previous_hour).reshape(self.X_previous_hour.shape[0], self.n_previous_hour_values, self.n_features)\n",
    "        self.X_previous_day = scaler_previous_day.transform(self.X_previous_day).reshape(self.X_previous_day.shape[0], self.n_previous_day_values, self.n_features)\n",
    "        self.X_previous_week = scaler_previous_week.transform(self.X_previous_week).reshape(self.X_previous_week.shape[0], self.n_previous_week_values, self.n_features)\n",
    "        self.X_previous_month = scaler_previous_month.transform(self.X_previous_month).reshape(self.X_previous_month.shape[0], self.n_previous_month_values, self.n_features)\n",
    "        self.y_bid = np.squeeze(scaler_y_bid.transform(np.expand_dims(self.y_bid, axis=1)))\n",
    "        self.y_ask = np.squeeze(scaler_y_ask.transform(np.expand_dims(self.y_ask, axis=1)))\n",
    "        \n",
    "    def transfer_to_tensor(self):\n",
    "        \n",
    "        self.X_date = torch.from_numpy(self.X_date)\n",
    "        self.X_now = torch.from_numpy(self.X_now)\n",
    "        self.X_previous_hour = torch.from_numpy(self.X_previous_hour)\n",
    "        self.X_previous_day = torch.from_numpy(self.X_previous_day)\n",
    "        self.X_previous_week = torch.from_numpy(self.X_previous_week)\n",
    "        self.X_previous_month = torch.from_numpy(self.X_previous_month)\n",
    "        self.y_bid = torch.from_numpy(self.y_bid)\n",
    "        self.y_ask = torch.from_numpy(self.y_ask)\n",
    "        \n",
    "    def cuda(self):\n",
    "        \n",
    "        self.X_date = self.X_date.cuda()\n",
    "        self.X_now = self.X_now.cuda()\n",
    "        self.X_previous_hour = self.X_previous_hour.cuda()\n",
    "        self.X_previous_day = self.X_previous_day.cuda()\n",
    "        self.X_previous_week = self.X_previous_week.cuda()\n",
    "        self.X_previous_month = self.X_previous_month.cuda()\n",
    "        self.y_bid = self.y_bid.cuda()\n",
    "        self.y_ask = self.y_ask.cuda()\n",
    "        \n",
    "    def cpu(self):\n",
    "        \n",
    "        self.X_date = self.X_date.cpu()\n",
    "        self.X_now = self.X_now.cpu()\n",
    "        self.X_previous_hour = self.X_previous_hour.cpu()\n",
    "        self.X_previous_day = self.X_previous_day.cpu()\n",
    "        self.X_previous_week = self.X_previous_week.cpu()\n",
    "        self.X_previous_month = self.X_previous_month.cpu()\n",
    "        self.y_bid = self.y_bid.cpu()\n",
    "        self.y_ask = self.y_ask.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069126e-e906-40e3-bd78-1036877f4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "        \n",
    "    with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_tuning_train_' + str(i) + '.pt'), 'rb') as file:\n",
    "        dataset_tuning_trains.append(torch.load(file, pickle_module=pickle))\n",
    "            \n",
    "    with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_tuning_validation_' + str(i) + '.pt'), 'rb') as file:\n",
    "        dataset_tuning_validations.append(torch.load(file, pickle_module=pickle))\n",
    "        \n",
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_eval_train.pt'), 'rb') as file:\n",
    "    dataset_eval_train = torch.load(filem pickle_module=pickle)\n",
    "    \n",
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_eval_validation.pt'), 'rb') as file:\n",
    "    dataset_eval_validation = torch.load(filem pickle_module=pickle)\n",
    "    \n",
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_eval_test.pt'), 'rb') as file:\n",
    "    dataset_eval_test = torch.load(filem pickle_module=pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5944eb4-9e4f-4355-9ce9-8970dbe0ebb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Y bid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e4640bf-0f47-434f-9091-9f41b0ebafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'y_bid'\n",
    "mlp.set_experiment(\"Forex EUR CHF Bid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b79c47-2019-4590-b06b-3945bbbe4d2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MLP 0 layer hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a62198aa-ce82-471b-84f5-448e44f61150",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd37b7-9881-4cd1-98db-34ec2ef3241e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ac642-f3e7-4aa9-bb1b-25133e151e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a437aa8-936a-40d6-a8a6-b8033f46fcb3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559bd5eb-2443-4722-8482-37728cb08b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3570e29-759a-4722-b2b8-e7099c78f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5058dbd3-3c97-4a1e-8811-6f9f33b3f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc514ff2-07dd-4d95-b5eb-96150fa8c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca5257-30f0-4776-88ea-1db9e98acb51",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62b2221d-9946-4b1a-bb96-e22acd326858",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3825a585-4a27-4d90-97bf-89207f639e65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Y ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec9fd5d-24b5-458d-91bb-024825f2dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'y_ask'\n",
    "mlp.set_experiment(\"Forex EUR CHF Ask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59abfc47-5902-484d-965c-686d62f8f31c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UI MlOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479dc04e-797a-4efb-b07b-b3f5e1c4632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ui(host='0.0.0.0', port=8085)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c8325-1401-4ea2-9fd8-3064a0c88e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
