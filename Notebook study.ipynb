{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c3012f-408c-4eee-aa6b-507d075d7d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pymlpipe.tabular import PyMLPipe\n",
    "from pymlpipe.pymlpipeUI import start_ui\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import optuna\n",
    "\n",
    "from helper import objective\n",
    "from helper import get_model \n",
    "from helper import evaluate_for_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ecfcc8-3912-4db4-9c17-28961a1d1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPOSITORY_DATA_RAW = 'data raw'\n",
    "REPOSITORY_DATA_PREPROCESSED = 'data preprocessed'\n",
    "REPOSITORY_STUDIES = 'studies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e23686-439f-4304-9498-c210e940b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = PyMLPipe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059dbed-6531-4b87-a1e1-cb9f20ac0623",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c95613-5dfd-4aec-9529-6978bb160198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForexDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_date, X_now, X_previous_hour, X_previous_day, X_previous_week, X_previous_month, y_bid, y_ask, idx, \n",
    "                 n_previous_hour_values, n_previous_day_values, n_previous_week_values, n_previous_month_values, n_features):\n",
    "        \n",
    "        self.X_date = X_date[idx].astype(np.int32)\n",
    "        self.X_now = X_now[idx].astype(np.float32)\n",
    "        self.X_previous_hour = X_previous_hour[idx].astype(np.float32)\n",
    "        self.X_previous_day = X_previous_day[idx].astype(np.float32)\n",
    "        self.X_previous_week = X_previous_week[idx].astype(np.float32)\n",
    "        self.X_previous_month = X_previous_month[idx].astype(np.float32)\n",
    "        self.y_bid = y_bid[idx].astype(np.float32)\n",
    "        self.y_ask = y_ask[idx].astype(np.float32)\n",
    "        self.n_previous_hour_values = n_previous_hour_values\n",
    "        self.n_previous_day_values = n_previous_day_values\n",
    "        self.n_previous_week_values = n_previous_week_values\n",
    "        self.n_previous_month_values = n_previous_month_values\n",
    "        self.n_features = n_features\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.y_bid.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.X_date[idx], self.X_now[idx], self.X_previous_hour[idx], self.X_previous_day[idx], \\\n",
    "               self.X_previous_week[idx], self.X_previous_month[idx], self.y_bid[idx], self.y_ask[idx]\n",
    "    \n",
    "    def fit_scalers(self, scaler_now, scaler_previous_hour, scaler_previous_day, scaler_previous_week, scaler_previous_month, scaler_y_bid, scaler_y_ask):\n",
    "        \n",
    "        return scaler_now.fit(self.X_now), scaler_previous_hour.fit(self.X_previous_hour), scaler_previous_day.fit(self.X_previous_day), \\\n",
    "               scaler_previous_week.fit(self.X_previous_week), scaler_previous_month.fit(self.X_previous_month), \\\n",
    "               scaler_y_bid.fit(np.expand_dims(self.y_bid, axis=1)), scaler_y_ask.fit(np.expand_dims(self.y_ask, axis=1))\n",
    "    \n",
    "    def scale(self, scaler_now, scaler_previous_hour, scaler_previous_day, scaler_previous_week, scaler_previous_month, scaler_y_bid, scaler_y_ask):\n",
    "        \n",
    "        self.X_now = scaler_now.transform(self.X_now)\n",
    "        self.X_previous_hour = scaler_previous_hour.transform(self.X_previous_hour).reshape(self.X_previous_hour.shape[0], self.n_previous_hour_values, self.n_features)\n",
    "        self.X_previous_day = scaler_previous_day.transform(self.X_previous_day).reshape(self.X_previous_day.shape[0], self.n_previous_day_values, self.n_features)\n",
    "        self.X_previous_week = scaler_previous_week.transform(self.X_previous_week).reshape(self.X_previous_week.shape[0], self.n_previous_week_values, self.n_features)\n",
    "        self.X_previous_month = scaler_previous_month.transform(self.X_previous_month).reshape(self.X_previous_month.shape[0], self.n_previous_month_values, self.n_features)\n",
    "        self.y_bid = np.squeeze(scaler_y_bid.transform(np.expand_dims(self.y_bid, axis=1)))\n",
    "        self.y_ask = np.squeeze(scaler_y_ask.transform(np.expand_dims(self.y_ask, axis=1)))\n",
    "        \n",
    "    def transfer_to_tensor(self):\n",
    "        \n",
    "        self.X_date = torch.from_numpy(self.X_date)\n",
    "        self.X_now = torch.from_numpy(self.X_now)\n",
    "        self.X_previous_hour = torch.from_numpy(self.X_previous_hour)\n",
    "        self.X_previous_day = torch.from_numpy(self.X_previous_day)\n",
    "        self.X_previous_week = torch.from_numpy(self.X_previous_week)\n",
    "        self.X_previous_month = torch.from_numpy(self.X_previous_month)\n",
    "        self.y_bid = torch.from_numpy(self.y_bid)\n",
    "        self.y_ask = torch.from_numpy(self.y_ask)\n",
    "        \n",
    "    def cuda(self):\n",
    "        \n",
    "        self.X_date = self.X_date.cuda()\n",
    "        self.X_now = self.X_now.cuda()\n",
    "        self.X_previous_hour = self.X_previous_hour.cuda()\n",
    "        self.X_previous_day = self.X_previous_day.cuda()\n",
    "        self.X_previous_week = self.X_previous_week.cuda()\n",
    "        self.X_previous_month = self.X_previous_month.cuda()\n",
    "        self.y_bid = self.y_bid.cuda()\n",
    "        self.y_ask = self.y_ask.cuda()\n",
    "        \n",
    "    def cpu(self):\n",
    "        \n",
    "        self.X_date = self.X_date.cpu()\n",
    "        self.X_now = self.X_now.cpu()\n",
    "        self.X_previous_hour = self.X_previous_hour.cpu()\n",
    "        self.X_previous_day = self.X_previous_day.cpu()\n",
    "        self.X_previous_week = self.X_previous_week.cpu()\n",
    "        self.X_previous_month = self.X_previous_month.cpu()\n",
    "        self.y_bid = self.y_bid.cpu()\n",
    "        self.y_ask = self.y_ask.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069126e-e906-40e3-bd78-1036877f4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tuning_trains = []\n",
    "dataset_tuning_validations = []\n",
    "\n",
    "for i in range(4):\n",
    "        \n",
    "    with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_tuning_train_' + str(i) + '.pt'), 'rb') as file:\n",
    "        dataset_tuning_trains.append(torch.load(file, pickle_module=pickle))\n",
    "            \n",
    "    with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_tuning_validation_' + str(i) + '.pt'), 'rb') as file:\n",
    "        dataset_tuning_validations.append(torch.load(file, pickle_module=pickle))\n",
    "        \n",
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_eval_train.pt'), 'rb') as file:\n",
    "    dataset_eval_train = torch.load(file, pickle_module=pickle)\n",
    "    \n",
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_eval_validation.pt'), 'rb') as file:\n",
    "    dataset_eval_validation = torch.load(file, pickle_module=pickle)\n",
    "    \n",
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_eval_test.pt'), 'rb') as file:\n",
    "    dataset_eval_test = torch.load(file, pickle_module=pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3b082-309a-4a42-8527-de28ce592f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'scaler_y_bid.pkl'), 'rb') as file:\n",
    "    scaler_y_bid = pickle.load(file)\n",
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'scaler_y_ask.pkl'), 'rb') as file:\n",
    "    scaler_y_ask = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5944eb4-9e4f-4355-9ce9-8970dbe0ebb1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Y bid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4640bf-0f47-434f-9091-9f41b0ebafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'y_bid'\n",
    "mlp.set_experiment(\"Forex EUR CHF Bid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b79c47-2019-4590-b06b-3945bbbe4d2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62198aa-ce82-471b-84f5-448e44f61150",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd37b7-9881-4cd1-98db-34ec2ef3241e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ac642-f3e7-4aa9-bb1b-25133e151e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a437aa8-936a-40d6-a8a6-b8033f46fcb3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559bd5eb-2443-4722-8482-37728cb08b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3570e29-759a-4722-b2b8-e7099c78f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5058dbd3-3c97-4a1e-8811-6f9f33b3f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc514ff2-07dd-4d95-b5eb-96150fa8c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca5257-30f0-4776-88ea-1db9e98acb51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b2221d-9946-4b1a-bb96-e22acd326858",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03652bf-e99a-4856-8073-9b7273ca6066",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b463debf-8a50-4741-9dec-7b6b2093cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3045dfc-46b5-45e9-b30c-65047f25ea69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd97c07-7eaf-48cc-9a72-3815c15e58df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaca65c-33fe-4097-850a-701b851a6a38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba20365-ef54-4a9b-b1ce-e58f9dd9ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc6695-26c8-4aa3-84ed-fbe8689a004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a72b2e0-6b00-4d06-bd69-cf68cbe94e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f72fca-eb81-43e2-a680-17e237be5d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aa9abc-90b1-4aad-be32-0277718d4bd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0545cdf-9e63-4d89-afea-8cf12a76213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01334c35-0ed4-47b0-98ba-f617982ca40d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f0b1f8-6476-4d7c-9845-b9bf353503af",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e581017-b268-4511-8fa1-08582ac20234",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bac224-7ea8-46b9-9265-c36e52f9a95f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a832fc5-5f74-4215-ab48-99357bda55e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84b7b2-e258-42c6-bc9f-ba0cd991ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad34ef-7f4c-4ec6-b034-bfa8e9d64a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53aeac6-4898-4582-b6e3-0fbdd41a1171",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb923d-c65b-4f58-b95a-a194717e7ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd45c43-061b-4bdf-b42f-e71d7d71edd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54cfc6-0c3c-4446-9490-55f2b872ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e343039-b2c4-475e-877a-dd31acdce43f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba045f2-89da-4049-ae8e-34c5b69fe9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5af836-abde-482d-a4f5-ccfd6e0092d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6a39b0-bab1-454e-87b7-fe28f3192d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95eb0fd-4b0d-4f80-b846-4874e2dad17b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26423208-4e05-4d81-8a46-3ad238490d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379c340-4817-43bc-83bc-1df9b3003cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ed58f-b4d5-44bf-82c5-2c4c5b8b213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8b0d5-0e98-4347-a18f-c97dc73c6158",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb640c17-1c84-42da-acb8-b9d972580764",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9b3c6a-0567-4af4-b2e3-8d513716801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232add51-af39-4648-bf91-4d086596f14d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315357fa-bce1-4666-b3cf-7eabdb717944",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe9251-b361-4079-9a2c-959bfcc60019",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d200fc83-eb7d-4335-949e-78949ce325f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae60004-1e94-487f-99b0-88d46ee2c546",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cfa080-d16b-46a4-97f5-db3ac8307c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e57678-6b58-4d00-8e45-aa8ac2dee40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8035f47-cca7-4895-a452-f2bac2719e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded0a5a-58e6-42d7-ad60-faa2241ef150",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15d352a-0a9b-4de5-817c-ee6b47dfcd70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a0e2ca-5746-4c87-8689-ce2d624eb804",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4163a561-b381-449e-933d-912475a8ba78",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3443b4c9-2114-418f-9c20-e2bbdb8a6bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a122d2e-57b5-4da4-b589-9b170d8c74cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fdeda3-e7c8-4997-b062-02d786459f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9415b5b-55fa-4a47-9158-fafe60a7a949",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0eb590-fa30-4501-9d72-6f4820cac7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2a47ba-e811-42d9-998b-0da8a821af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693fbca-95db-497f-a02a-1fc9e99b6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f661b-8dfc-4544-92bf-f392f1f68d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a558051-6106-4d01-abc3-20c2c0737988",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957387d7-2bee-4d57-a84a-b0400c45621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d2836-0387-41b6-988c-3de5f127464e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e6180-3088-4c93-865b-ee4c2775daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae4f658-9749-471c-9eea-07a896f43e53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b5b68-200d-4ded-9337-f3814c15139e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8311de05-c47e-4c15-bd01-f88f2cc6bf5c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6af114-f0c7-49e9-89cf-7e8a95b1347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b98d7-c460-4ca1-85e5-1db3c1605e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e3bd6-c10f-405d-9252-f73abe82e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da8c3e-aa8e-4db7-bea3-9fac197bb0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc98615-ad54-40da-82dc-ff7cb0a5485d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663b3621-4253-407b-986b-f476d6f0a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180a3b1-09f8-4093-8a06-00dd04c30148",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13121d80-dedf-44c2-b2ca-1b0cc1779685",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81346c3-b8b3-40c3-a826-9b14c25c8929",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becc699b-79ee-4931-8bf2-36922f9b4c33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d94d98-d708-456e-b4bd-b13eb7b9a1d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13afaf45-1dc0-46ca-943d-e519b7978b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea32c67e-7623-4f2f-b71e-de6fc6d6292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ce8cb7-ef48-411e-91ad-c4f4031f6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c5364-5bae-4043-98c1-5b6896f1efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80138b1-6a0c-4975-ae5e-1a133a9d2572",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce116b43-1d51-407c-848a-a96a82f18e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5ea023-a21f-45d8-af37-b1f672205aed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f6bf4-ee9a-4ba9-8fc0-06b9422b6748",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818a154-ed62-4c0f-8ca6-1f9fac9367e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1410b1-91c9-4aaa-b771-ea4823d767f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892e48c0-9fc5-4042-9115-a474a5f3d806",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b80ff30-cef1-4787-9268-687107503c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5068eaa3-d80d-4850-b434-7326abc08dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8a3f0-439c-4733-9ff1-09510e545602",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085afe78-c54a-4ace-a81f-32982a7cf4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b192e25-12db-4d50-a31a-5cf74b11719c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48771e81-baf3-47cc-9569-bca2300c2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772cbd16-ee09-4fa5-b4b9-a23fbedc2a1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9e9dad-d7b4-4d36-acbc-e9f2ea959451",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de679be8-e019-4bbc-9425-3515d571889e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bcae73-0124-4764-97e3-7475a36122ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2c60f5-28f3-46df-9e05-16a579626a49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7b1eb-a794-4a74-a3d4-adcc85c2499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4122f064-fb79-461c-9617-2eec386d8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeabc90-a331-41d8-b838-814a64e33031",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f030be-7c89-4e5e-b239-754cdfc0f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c33972-102c-4e76-8f85-cf6c58ffd16f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfeeab-1082-4d9b-b012-e32975c760de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a4f0af-b084-44f6-bf0c-407762f3a5e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89753a56-b64a-418a-8694-73d162c600fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c80e40f-e7a8-49ef-b55c-d8103d33175e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c840be5f-ef63-42eb-b642-17ca24cdc6c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a04db1b-6faf-4be2-8cd1-57183b3e83bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ef2cb-4597-4106-b9bc-922058580bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31996b15-af99-4745-81c5-b35bfb6b957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f8f4d7-b1c1-4245-9cf5-068a227986dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0380d-09e0-4127-98c9-72c2ae7e3080",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3012cf-baaf-4c12-9b0a-e056ad7bcaa8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e084abce-625a-44ba-83a1-31d23c00cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c16aff-87a7-4b7d-9b56-ce0482058ba1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3cd941-029b-43c8-8c18-006f5818894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab81b5-f444-4737-87fd-29e0e0d6cc5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05dc466-f91a-4a6b-9be8-884d7c4f1a19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31587819-1ce9-4423-ae03-44c4fc8de120",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a510b8df-2306-4c28-b917-9b04c7ff41b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07435ef-421c-47f5-a7dd-16fb1fc1880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066c7d2-11be-4a7e-9362-c1b46fac408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62007004-3df3-4086-a08b-ff31730f2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b13dc92-b12c-4e00-92c2-4567753bd72f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f199fa1-6fca-41ac-b67c-d1c12e5b5ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed69ca3-08d0-4a5d-bd84-76b6599dcea1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2f4bd-a4e2-42e5-ac32-d09fac62655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c719ea6f-74ce-46b7-b54a-293b4a4c4043",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985022a5-db78-4b84-92e8-9161b88b02f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d8e6b-ce74-4c0e-a9b2-1b16db84316d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a71cc-4414-4287-bdaf-f4b3baca28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8378dd66-1ee1-4130-8bd2-3b89bb2a1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cf3e27-54ab-497d-ba7a-821d27bef8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b914f9-6729-4e83-baa3-6a2afc1cfc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a828eb11-55a0-4d2f-a056-d5709cc0b70e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c2288f-c08e-492c-babe-491718742607",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a7d842-f4f6-4a13-9afa-2259b0bdc8f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a204fd-2b2e-44bf-b329-88448253c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2189f0-300a-4afa-aa02-abc462f6d80d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34949b-5204-40a9-a54c-e533772599a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec62e68-7255-4d62-9a9e-1542d05dce97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5920d4-a041-460c-8071-b58d12d73566",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0abecc5-c214-426f-9547-0b5ec08bac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da6e8a-8e81-4b5a-b63b-d3965692d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f51af3-1d53-46eb-8f01-29262dc874e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e574a487-edde-4a3d-852e-f4e545d61972",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea6a2a-0888-4513-9577-d37c4bb4b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12966e57-cacd-49ae-b2da-159437089550",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6764a5d-e4df-430c-9ac1-095b94ef744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0a6a82-09da-4b63-919b-3c45fedb3186",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da03b982-2ab4-4b83-afb3-56f796fa6bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8109957-af4d-4920-ad60-3aad91891f5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97734f7-27ca-4e74-9074-be36d89f5130",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2403e077-77ab-40c3-b522-8918959b923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c3729-a0a6-4b4d-84df-303cb817c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372c8b0f-c4a6-42cd-a900-a07f36cfaf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3e9671-0b44-436c-9421-38246562e9b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c21900-3075-4569-9c53-9724f375642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486f6d1-f764-4b00-856e-7b9d059e9c3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d125dca-1700-4827-bb7b-d1ed1aeed7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe7d8df-78db-4c6b-b83e-5b2eed347d79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d5884-4bef-4927-b93f-cf6694b33b17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6521bc73-95a9-4675-af57-bf22b5679f30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d458b-eded-4864-afbb-2bbec4a81ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c7b8be-44af-426b-98b0-d40b11a26b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc4843-68ed-4e31-919e-4e8ca791de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d52d80a-edc7-4d86-bf8c-6d871b21a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31223e5d-3332-43d1-8b57-dda3fcb04222",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a347b54e-5d38-4e7b-ae16-c674ec6232a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3825a585-4a27-4d90-97bf-89207f639e65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Y ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec9fd5d-24b5-458d-91bb-024825f2dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'y_ask'\n",
    "mlp.set_experiment(\"Forex EUR CHF Ask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5e7b9-0bc8-4d90-82cb-29d4fa08b248",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa421d-df22-4166-852b-657a8f96e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb1a22-f771-4efa-a133-a2a812829c3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cdb2b1-a5b3-4c7d-94a2-0f0cded8b9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a7ea8-f883-4381-85b4-38bd6afc1b2c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616b526-256e-453b-a701-4a0d5ecae608",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323818cb-2479-4af8-81a4-cc07e8308719",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e6eca-5f65-461a-adb2-bd23964991fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af479ea6-1d76-43ec-8248-12c041a97dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5412a486-47eb-44ef-b666-f9f186689947",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69e98a-970b-4c42-89b0-06d3f4f8fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cc6b83-27ef-4533-9404-47f732df1e0c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbcf535-ca42-4a82-8044-e1c0df9c90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1eaab5-2b68-47be-a9b3-d432c1bdf6be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def6cbfc-e262-428f-9f54-bd84e97c611b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd8b2d9-40d0-4e09-a10d-07f62c47072d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7690bc9-588e-4049-897b-6bbac6d63db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eee32df-3829-475d-9c30-e9f962957e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e7290-ec16-429e-b0fe-5b0fc605db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceef4ff-bc32-4351-869e-2fdb34705d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee6d3ec-67fe-48ae-9a9f-2eddf97d172e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475ecef-8c7a-4a83-9967-5aae217f8290",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b32a63-462c-4ad2-a393-66b27f8c9af9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9216ea2-7227-4b42-b3f2-c1d9efa57204",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6b879a-5330-4c43-83af-2495235f0a29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4746865-4cbe-45c5-acd4-1c0f190223cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098567ab-3789-4e6f-96a3-020eb379d77c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44db5fc1-abbf-411f-bd3a-b1728bee4fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b882e14-5b77-4a84-8e22-9d03177b1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130cea7a-276e-4637-b4ee-cdd0fa134eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef757087-dab3-4855-91f5-00c084ddff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5f59ce-5b9f-4297-aa40-9fd69f8ea2f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9691a64-1a25-45a5-a68b-eb92b01c1de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f01a981-c26a-4aff-b06d-f6bb7171ed41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers hour memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed92b46-daf2-452e-8c0b-a50ea04c4b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3HourMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f090cc-c2c0-408a-96c4-9af0a8b0f84e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64992e81-ef1c-474d-b2d5-0c1d081c1348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe5d69-0d21-435d-9684-ef4b2c22bade",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef4d6eb-47c2-4777-b5a6-fd5438ac9c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b5342-e5a5-44e6-899e-70c6ef52a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c2531-a2d4-44be-bb49-2f1cc2400eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00668b4b-d263-4dfc-bd02-2624a53e2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bdb3d1-b98f-42ce-b416-565b6a9c9066",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8589d4f-586f-4676-a36c-9f91a7a85787",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d8ca96-b0fc-451e-b8aa-7518c4f6d1f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f85ba4-f5d8-4ba4-ab6a-ee35b3970dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7aef8d-0c31-4c3b-88fd-f6ff7ba513ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec9417-ab10-4ccf-be6a-e3fd34140038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebfd0bc-8ac6-4efd-9c56-ff6a3856467a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ac6bc-b88e-4735-8772-e30435035596",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee5a1e0-8f27-4bac-a525-9d405e40d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c5779-e9f9-4d6d-be2e-e66dd97f1844",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb8ec6-eb73-48ec-8ccd-c6a02ea5b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d87a7ab-0bde-4806-952b-4c93279d3426",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7550d8-0fe4-4f5a-88b1-a92e736702fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d123550-b48f-4160-83a9-901525f59eb4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92ab16-063e-41a7-ad1f-4df72d0e0755",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e389dead-a542-4ced-9a88-8432f4ce9bd0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9281749-4014-4d7a-896f-b57175f656a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025093d5-c99b-4e39-8d46-36defae25e2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86af838a-5659-4c79-986d-d879b69c36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4859b-6600-4e22-a83e-e01729749cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa4b920-c4ad-4380-9fc4-32dae37876d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647dc07a-7c21-4caa-a7c9-0bff49a5034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de151c-c9c0-451a-b8e5-56d1837d6323",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31467ec5-0d33-4d26-a8f5-39f4600bc72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971d4a9-a89b-43ab-b42e-a2cad23da536",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20bda4-d875-464a-9cbe-f94aa1767905",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe56551e-9c1b-43bf-a8d6-0cc48cb5c1f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060bfee8-0144-4f12-99e5-0e1feac4b7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fbe97f-3067-4cc7-ae6b-bdbe50b03fd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ef459-2905-4a3b-8776-76692421e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d446d-d6f2-44ad-bb68-8d466383e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1aec7f-923d-4737-ba6f-cdf7ca647f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c63717-65a7-4815-9626-41ff2ca67127",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada62b5f-e33a-4530-a11e-3cf93e7d6f06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88f654-65e1-44fa-b51c-8b2a64c1e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb09ad8-99cc-45f8-88eb-909a887be42c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers day memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d95ddc-e76e-43b6-9559-1e25c39b12a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3DayMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26135a30-6ce1-49de-8938-616f2d2ee848",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10c9d71-d0c0-4f36-b56e-f60a286d1c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc02b163-f148-4756-b98e-50604543030e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cbb760-328d-4e9b-b7c9-114d7a683d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec020be-0f80-4301-a29b-751b452cc766",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b79d76-a759-4557-a7ab-89825b1284bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d1eb6-da8a-4503-85ee-fd8b25d02b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f7882c-627c-4d07-9d57-0626bbbc60ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b30379-defb-4453-a95a-316b4f37c2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bac25d2-5d51-478f-8078-a325c7cc7690",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d77369-b81a-4c46-a3af-88267bf0c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793f988b-7b81-47c1-8a12-7e1e43bf4727",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b6020-628c-45e9-92ae-86f12a9e18b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f1620a-625d-4b80-a5ab-b4721a170e41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a38561-136d-4199-b861-6941cb8d4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de67f9-97c5-457c-806a-2f3e457f65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849372ee-57aa-4e8a-9496-011b9a520aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e599e168-d3ac-4d8b-ad68-c804a8d8c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ac869f-f1c5-4d0a-bda0-13243e4451b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f69c5d-9420-4bd1-8939-89a7181c71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4290ff-7353-4d32-9efa-dd2c7f592fe4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52fd4a0-6912-487b-be87-7d9c6c8e5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb06f5-121f-4ab8-96eb-0e0a532921ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143aaeeb-06eb-4ebd-b3c7-cc846f84deaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7dd44e-44bb-483a-b028-1123e3dc4726",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d232e3a-e3c1-4ee1-8cd5-79dff31e01ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78ff0c-1378-490e-af2a-c62aea533bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf75bd-2852-4f4b-b307-ce82eb58f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ff233b-6495-4c45-8ec4-9eea35ad9741",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba4b0e-3c0c-4322-b1d8-d82ea32fdfda",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70bcd34-e4e8-4334-91d6-c44abe38bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409df207-cf37-4bb7-aede-33bb0808d918",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b212900-b330-4201-a902-19735a8d51e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c293d-55a6-4cfb-9cd0-948b90fe8e0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53117bf2-3905-4ca1-b156-9f06e1627739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ecded-3da8-4037-a5b6-2e46d4a6f98f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff164e-5b96-4a61-b330-031ceaac0edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9898dd35-b085-4ecd-ad00-c767b2b13b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236f235-8a0f-4d31-88d7-c3819030d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56811659-bad6-45ba-a3ba-076db19a470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dd5f96-136b-4a46-9045-ff007fbcc5e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a4710b-610e-44e3-8d45-0e4925b84a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8b538-1e00-4b43-a453-1f9b50098730",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers week memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83362c1c-8b3c-4b21-9276-647b2cc7a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3WeekMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd19abeb-86ff-4959-8078-cb218ccb5901",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1aeb3f-479b-4adb-99d8-a50c22f05c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe4adc0-8246-42cc-9e0c-6770c0e76543",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc812cfd-5058-4c01-9352-20a5fb214b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3364a8c-f28e-4526-bc59-38c8c0d74e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69865fcd-ef94-4f47-abad-8ad39655ec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f940a7-0770-41bc-b90f-3f2e92bf57ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26713c1-8036-42fc-bd71-e8cfbe33b1f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f27fc9-6a96-4a13-aff2-90941258d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ae0341-8315-4b69-9077-8f134c6b565d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 0 layer month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60efbc11-5e2e-4dfa-ab99-d2bd4c24f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP0MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeed15e-3518-4b68-8e7b-ddb21cfb4bea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7333d14d-d9da-4aa6-95f3-2c65fc5928c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c4fae-dc88-4325-9e96-650ce7c75b12",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919726bc-8ee3-4f1e-b05d-0bee5ea29546",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd634cb6-b797-4128-831d-60ef415d61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb7f96-326c-44e8-815f-9cb9fa5bde5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9c88b0-0328-4146-ac06-2ca9c92ba453",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b866a6d2-e07e-48e1-8c8a-07bbe29c47db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f1fe2-d53e-4905-98ee-3ee5d829f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c231a-8a9d-427c-b583-cb485b1eeb6f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 1 layer month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c719f07-b93c-4a84-9ab7-1e72e28cf898",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP1MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a403310-7b5b-4fff-a92c-9e28f46189c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e09b68-e759-40e4-adfd-3c7d995315d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b265ae-479c-4a75-852d-617de9fb837c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fd74ba-5348-47f0-b322-03ecdae0f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2781bf8-9d01-4bf9-a81e-34f75f128f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550d440-a307-4995-882a-f6bb12c470f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e817d6f-28a7-4a38-813d-ebe789b6754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db88206-93e0-4c87-8759-7ecf59ed6556",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc5600-b5e1-4e5c-a60e-beffdddea048",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e441f6-e60b-4503-94c0-13a0ccd11343",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 2 layers month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf1043-a311-4b7a-9c2d-9ac680589e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP2MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab38687-c148-4e6c-947c-dd5a795f4f82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f93f4-a8f7-46a6-8302-319492d8c809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b967bef-65dd-4fb9-8856-bb795ddb62a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a8359-28fc-4caf-b549-ad908d0d9a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f434a067-0dce-42c5-bc7c-5728e01434a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ded31a-3b81-42ce-8d00-3a0a6b4cf10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b600fe5-b442-4da9-9bda-401a75e5a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac8daa-2a59-4ce2-944c-d318adaf6f76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c5e6f-6d7d-4ceb-8817-9a3a7cda1eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b89129a-5bbb-4c41-a9fa-144b393fa273",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP 3 layers month memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7048ba8b-642f-4ce4-9ec8-ea6ceb396712",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP3MonthMemory'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb664e74-b381-4cd7-97e0-57bea879a0dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ff2af-666b-4346-b095-85302564b967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            TARGET, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b4013d-53e1-416c-96fc-ab0668a5ff01",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5b9f99-3b27-4f27-bec8-0875e62428e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be4dc24-ed65-4dc0-af51-d742fc07a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da7c71-28f5-4946-9d48-abb809dded5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e4647-0373-407b-9a18-de6729f39480",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d03a6-9e6b-429d-bbc3-498af204a34f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c876b7-56a0-4840-9425-1720a44fd652",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, TARGET, 'study ' + TARGET + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, loss_test_mse, loss_test_mae, loss_test_mse_unscaled, loss_test_mae_unscaled, relative_error, max_error_absolute, max_error_relative, epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_target=scaler_y_bid if TARGET == 'y_bid' else scaler_y_ask, \n",
    "    target=TARGET, \n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=study.best_params['batch_size_train'], \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run():\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": epoch\n",
    "    })\n",
    "    mlp.log_metrics({\n",
    "        \"MAE normalized * 1e6\": loss_test_mse * 1e6,\n",
    "        \"MSE normalized * 1e6\": loss_test_mae * 1e6,\n",
    "        \"MAE absolute * 1e6\": loss_test_mse_unscaled * 1e6,\n",
    "        \"MSE absolute * 1e6\": loss_test_mae_unscaled * 1e6,\n",
    "        \"Relative error * 1e6\": relative_error * 1e6,\n",
    "        \"Max error absolute * 1e6\": max_error_absolute * 1e6,\n",
    "        \"Max error relative * 1e6\": max_error_relative * 1e6\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59abfc47-5902-484d-965c-686d62f8f31c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UI MlOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479dc04e-797a-4efb-b07b-b3f5e1c4632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ui(host='0.0.0.0', port=8085)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c8325-1401-4ea2-9fd8-3064a0c88e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
