{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c3012f-408c-4eee-aa6b-507d075d7d36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pymlpipe.tabular import PyMLPipe\n",
    "from pymlpipe.pymlpipeUI import start_ui\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import optuna\n",
    "\n",
    "from helper import objective\n",
    "from helper import get_model \n",
    "from helper import evaluate_for_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ecfcc8-3912-4db4-9c17-28961a1d1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPOSITORY_DATA_RAW = 'data raw'\n",
    "REPOSITORY_DATA_PREPROCESSED = 'data preprocessed'\n",
    "REPOSITORY_STUDIES = 'studies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e23686-439f-4304-9498-c210e940b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = PyMLPipe()\n",
    "mlp.set_experiment(\"Forex EUR CHF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059dbed-6531-4b87-a1e1-cb9f20ac0623",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c95613-5dfd-4aec-9529-6978bb160198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForexDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_date, X_now, X_previous_hour, X_previous_day, X_previous_week, X_previous_month, y_bid, y_ask, idx, \n",
    "                 n_previous_hour_values, n_previous_day_values, n_previous_week_values, n_previous_month_values, n_features):\n",
    "        \n",
    "        self.X_date = X_date[idx].astype(np.int32)\n",
    "        self.X_now = X_now[idx].astype(np.float32)\n",
    "        self.X_previous_hour = X_previous_hour[idx].astype(np.float32)\n",
    "        self.X_previous_day = X_previous_day[idx].astype(np.float32)\n",
    "        self.X_previous_week = X_previous_week[idx].astype(np.float32)\n",
    "        self.X_previous_month = X_previous_month[idx].astype(np.float32)\n",
    "        self.y_bid = y_bid[idx].astype(np.float32)\n",
    "        self.y_ask = y_ask[idx].astype(np.float32)\n",
    "        self.n_previous_hour_values = n_previous_hour_values\n",
    "        self.n_previous_day_values = n_previous_day_values\n",
    "        self.n_previous_week_values = n_previous_week_values\n",
    "        self.n_previous_month_values = n_previous_month_values\n",
    "        self.n_features = n_features\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.y_bid.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.X_date[idx], self.X_now[idx], self.X_previous_hour[idx], self.X_previous_day[idx], \\\n",
    "               self.X_previous_week[idx], self.X_previous_month[idx], self.y_bid[idx], self.y_ask[idx]\n",
    "    \n",
    "    def fit_scalers(self, scaler_now, scaler_previous_hour, scaler_previous_day, scaler_previous_week, scaler_previous_month, scaler_y_bid, scaler_y_ask):\n",
    "        \n",
    "        return scaler_now.fit(self.X_now), scaler_previous_hour.fit(self.X_previous_hour), scaler_previous_day.fit(self.X_previous_day), \\\n",
    "               scaler_previous_week.fit(self.X_previous_week), scaler_previous_month.fit(self.X_previous_month), \\\n",
    "               scaler_y_bid.fit(np.expand_dims(self.y_bid, axis=1)), scaler_y_ask.fit(np.expand_dims(self.y_ask, axis=1))\n",
    "    \n",
    "    def scale(self, scaler_now, scaler_previous_hour, scaler_previous_day, scaler_previous_week, scaler_previous_month, scaler_y_bid, scaler_y_ask):\n",
    "        \n",
    "        self.X_now = scaler_now.transform(self.X_now)\n",
    "        self.X_previous_hour = scaler_previous_hour.transform(self.X_previous_hour).reshape(self.X_previous_hour.shape[0], self.n_previous_hour_values, self.n_features)\n",
    "        self.X_previous_day = scaler_previous_day.transform(self.X_previous_day).reshape(self.X_previous_day.shape[0], self.n_previous_day_values, self.n_features)\n",
    "        self.X_previous_week = scaler_previous_week.transform(self.X_previous_week).reshape(self.X_previous_week.shape[0], self.n_previous_week_values, self.n_features)\n",
    "        self.X_previous_month = scaler_previous_month.transform(self.X_previous_month).reshape(self.X_previous_month.shape[0], self.n_previous_month_values, self.n_features)\n",
    "        self.y_bid = np.squeeze(scaler_y_bid.transform(np.expand_dims(self.y_bid, axis=1)))\n",
    "        self.y_ask = np.squeeze(scaler_y_ask.transform(np.expand_dims(self.y_ask, axis=1)))\n",
    "        \n",
    "    def transfer_to_tensor(self):\n",
    "        \n",
    "        self.X_date = torch.from_numpy(self.X_date)\n",
    "        self.X_now = torch.from_numpy(self.X_now)\n",
    "        self.X_previous_hour = torch.from_numpy(self.X_previous_hour)\n",
    "        self.X_previous_day = torch.from_numpy(self.X_previous_day)\n",
    "        self.X_previous_week = torch.from_numpy(self.X_previous_week)\n",
    "        self.X_previous_month = torch.from_numpy(self.X_previous_month)\n",
    "        self.y_bid = torch.from_numpy(self.y_bid)\n",
    "        self.y_ask = torch.from_numpy(self.y_ask)\n",
    "        \n",
    "    def cuda(self):\n",
    "        \n",
    "        self.X_date = self.X_date.cuda()\n",
    "        self.X_now = self.X_now.cuda()\n",
    "        self.X_previous_hour = self.X_previous_hour.cuda()\n",
    "        self.X_previous_day = self.X_previous_day.cuda()\n",
    "        self.X_previous_week = self.X_previous_week.cuda()\n",
    "        self.X_previous_month = self.X_previous_month.cuda()\n",
    "        self.y_bid = self.y_bid.cuda()\n",
    "        self.y_ask = self.y_ask.cuda()\n",
    "        \n",
    "    def cpu(self):\n",
    "        \n",
    "        self.X_date = self.X_date.cpu()\n",
    "        self.X_now = self.X_now.cpu()\n",
    "        self.X_previous_hour = self.X_previous_hour.cpu()\n",
    "        self.X_previous_day = self.X_previous_day.cpu()\n",
    "        self.X_previous_week = self.X_previous_week.cpu()\n",
    "        self.X_previous_month = self.X_previous_month.cpu()\n",
    "        self.y_bid = self.y_bid.cpu()\n",
    "        self.y_ask = self.y_ask.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069126e-e906-40e3-bd78-1036877f4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tuning_trains = []\n",
    "dataset_tuning_validations = []\n",
    "\n",
    "for i in range(4):\n",
    "        \n",
    "    with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_tuning_train_' + str(i) + '.pt'), 'rb') as file:\n",
    "        dataset_tuning_trains.append(torch.load(file, pickle_module=pickle))\n",
    "            \n",
    "    with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_tuning_validation_' + str(i) + '.pt'), 'rb') as file:\n",
    "        dataset_tuning_validations.append(torch.load(file, pickle_module=pickle))\n",
    "        \n",
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_eval_train.pt'), 'rb') as file:\n",
    "    dataset_eval_train = torch.load(file, pickle_module=pickle)\n",
    "    \n",
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_eval_validation.pt'), 'rb') as file:\n",
    "    dataset_eval_validation = torch.load(file, pickle_module=pickle)\n",
    "    \n",
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'dataset_eval_test.pt'), 'rb') as file:\n",
    "    dataset_eval_test = torch.load(file, pickle_module=pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3b082-309a-4a42-8527-de28ce592f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'scaler_y_bid.pkl'), 'rb') as file:\n",
    "    scaler_y_bid = pickle.load(file)\n",
    "with open(os.path.join(REPOSITORY_DATA_PREPROCESSED, 'scaler_y_ask.pkl'), 'rb') as file:\n",
    "    scaler_y_ask = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb5967c-1dd4-4f70-bc83-1beb822a444c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e08d5b-badd-4c79-929f-0411542d7831",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MLP'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ced37-b64a-4e39-999e-c10ced28bb7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b121c70c-c8dd-4930-87f5-07c40a926910",
   "metadata": {
    "tags": []
   },
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, 'study ' + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, 'study ' + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, 'study ' + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb8f78-51a7-4ad5-be12-042354c61b6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb310c84-6495-4c40-a18f-772f77fbf1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, 'study ' + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, 'study ' + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a02a2d-e40e-486a-b1ca-b917aa5277b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7071583b-823a-4b21-98ae-68177ff6833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c688f5f-16b0-45e4-923c-1f1a3c4561d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea5f83c-56c3-4110-ab37-9bf30272aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best score: {}\".format(study.best_value))\n",
    "print(\"Best params: {}\".format(study.best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb68d4a-2ab3-486d-a52e-20454903a614",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee91b01-fe40-4ee2-a5a6-50a74ca54acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, 'study ' + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, 'study ' + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, results, best_epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_y_bid=scaler_y_bid,\n",
    "    scaler_y_ask=scaler_y_ask,\n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=int(2 ** study.best_params['batch_size_train']), \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "results['7. MSE tuning normalized'] = study.best_value\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run(runid=MODEL_NAME + \"_\" + str(MODEL_VERSION)):\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": best_epoch\n",
    "    })\n",
    "    mlp.log_metrics(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f253b4b-658e-406c-b9aa-2ea4789abea6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# TransformerMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfb2968-63fe-4af5-a51a-68b1a2dd4e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'TransformerMLP'\n",
    "MODEL_VERSION = 1.0\n",
    "TUNING_PATIENCE = 5\n",
    "TUNING_EPOCHS = 50\n",
    "TESTING_PATIENCE = 10\n",
    "TESTING_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042725c8-1c42-409c-835a-1a8ac2e2f8e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d523d4-6573-4f1c-a384-470b98de31f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, 'study ' + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, 'study ' + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial, \n",
    "            dataset_tuning_trains, \n",
    "            dataset_tuning_validations, \n",
    "            MODEL_NAME, \n",
    "            patience=TUNING_PATIENCE, \n",
    "            epochs=TUNING_EPOCHS),\n",
    "        n_trials=1, \n",
    "        timeout=None, \n",
    "        n_jobs=1)\n",
    "    \n",
    "    with open(os.path.join(REPOSITORY_STUDIES, 'study ' + ' ' + MODEL_NAME + '.pkl'), 'wb') as file:\n",
    "        pickle.dump(study, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15b4224-b159-47e5-a77f-07a2f2f04510",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba7994c-8e65-4a26-88a8-a183f1a03671",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, 'study ' + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, 'study ' + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c7d59c-3e2f-4491-bc30-21bd85081b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b8893-af77-4b11-97a2-f3654289477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51aa167-e2c4-45e4-aa73-90aca365bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e94d395-a488-4b7f-ac50-dd19b183057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best score: {}\".format(study.best_value))\n",
    "print(\"Best params: {}\".format(study.best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e198d8-6ab0-4500-98de-17386c5a767b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8975187f-2a20-4e83-af65-120861d5ae43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(REPOSITORY_STUDIES, 'study ' + ' ' + MODEL_NAME + '.pkl')):\n",
    "    with open(os.path.join(REPOSITORY_STUDIES, 'study ' + ' ' + MODEL_NAME + '.pkl'), 'rb') as file:\n",
    "        study = pickle.load(file)\n",
    "else:\n",
    "    raise Exception(\"Study do not exists\")\n",
    "\n",
    "model = get_model(MODEL_NAME, **study.best_params)\n",
    "\n",
    "model, results, best_epoch = evaluate_for_testing(\n",
    "    model, \n",
    "    dataset_eval_train, \n",
    "    dataset_eval_validation, \n",
    "    dataset_eval_test, \n",
    "    scaler_y_bid=scaler_y_bid,\n",
    "    scaler_y_ask=scaler_y_ask,\n",
    "    optimizer=study.best_params['optimizer'], \n",
    "    batch_size_train=int(2 ** study.best_params['batch_size_train']), \n",
    "    batch_size_validation=dataset_eval_validation.__len__(), \n",
    "    batch_size_test=dataset_eval_test.__len__(), \n",
    "    learning_rate=study.best_params['learning_rate'], \n",
    "    weight_decay=study.best_params['weight_decay'], \n",
    "    patience=TESTING_PATIENCE, \n",
    "    epochs=TESTING_EPOCHS)\n",
    "\n",
    "results['7. MSE tuning normalized'] = study.best_value\n",
    "\n",
    "mlp.set_version(MODEL_VERSION)\n",
    "\n",
    "with mlp.run(runid=MODEL_NAME + \"_\" + str(MODEL_VERSION)):\n",
    "    \n",
    "    mlp.pytorch.register_model(MODEL_NAME, model)\n",
    "    mlp.log_params({\n",
    "        \"n_previous_hour_values\": study.best_params.get(\"n_previous_hour_values\", 0),\n",
    "        \"n_previous_day_values\": study.best_params.get(\"n_previous_day_values\", 0),\n",
    "        \"n_previous_week_values\": study.best_params.get(\"n_previous_week_values\", 0),\n",
    "        \"n_previous_month_values\": study.best_params.get(\"n_previous_month_values\", 0),\n",
    "        \"optimizer\": study.best_params['optimizer'],\n",
    "        \"batch_size_train\": int(2 ** study.best_params['batch_size_train']),\n",
    "        \"learning_rate\": study.best_params['learning_rate'],\n",
    "        \"weight_decay\": study.best_params['weight_decay'],\n",
    "        \"patience\": TESTING_PATIENCE,\n",
    "        \"epochs\": TESTING_EPOCHS,\n",
    "        \"effective epochs\": best_epoch\n",
    "    })\n",
    "    mlp.log_metrics(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59abfc47-5902-484d-965c-686d62f8f31c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UI MlOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479dc04e-797a-4efb-b07b-b3f5e1c4632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ui(host='0.0.0.0', port=8085)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
